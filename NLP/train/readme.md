Описание процесса обучения модели.

Перенести в папку все ноутбуки, котороые участвуют в тренировке. 
Остальные выкинуть.

Скачать датасет рецептов. поместить его в папку датасет.

Скача датасет диалогов. Перенести его в папку датачсет.

Чтобы привести датасет в формат подходящий для обучения модели. загружаем его в папку. Запустить код в ноутбуке.

Обучение модели проходит в два этапа.
1. Обучение модели на по инструкции.
2. Обучение модели на диалогах.

На вервом этапе модель учится выдавать ответы на запросы о приготовлении того или иного блюда.
На втором - вести диалог от имени персонажа, Кибер-бабушки. На данном этапе модель учится соблюдать в диалоге стиль общения персонажа.

## Подготовка датасета
### Подготовка датасета с рецептами.
Датасет с рецептами - Kaggle
Скачать с kaggle с датасетом all_recepies_inter.csv.zip и разархивировать его в папку `train`.

Выполнить код из ноутбука - receptes_dataset_prepere.ipynb

В результате должен появиться кактлог train/datasets с 6-ю файлами в формате jsonl. 

### Подготовка датасета с диплогами.
Датасет с диалогами персонажей - HuggingFace
ВЫполнить код из ноутбука - dialoges_dataset_prepere.ipynb

## Обучение модели
Для экономии вычислительных ресурсов обучение не исходной модели а адаптера LoRa.

Базовая модель - TheBloke/Llama-2-7B-fp16.

Данная модель не очень хорошо поддходит для русского языка. 
Пошел не неболшую хитрость. IlyaGusev/saiga2_7b_lora обученноую на этой модели.


Оба этапа обучения модели описаны в файле train_adapter.ipynb
